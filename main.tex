\documentclass[a4paper]{book}


%% Mise en page
\addtolength{\hoffset}{-0.8cm} \addtolength{\textwidth}{2.8cm}
\addtolength{\voffset}{-1.4cm} \addtolength{\textheight}{3.3cm}
\addtolength{\evensidemargin}{-1.9cm}

%% Packages
%\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{theorem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage[sectionbib]{natbib}
%\usepackage{multibib}
\usepackage{graphicx}
\usepackage{pstricks}
\usepackage{psfrag}


\usepackage{textpos}
\usepackage{graphicx}
\usepackage{xcolor,colortbl}
\usepackage{pgfgantt}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{xcolor,colortbl}

\definecolor{bleu}{rgb}{0.2,0,0.2}
\definecolor{macouleur}{rgb}{0.5,0.5,0.5}
 \definecolor{greenz}{cmyk}{1.0,0,1.0,0.4}
 \definecolor{purplez}{cmyk}{0.0,1.0,0.0,0.1}

%% Theorem like
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{ex}{Example}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{definition}{Definition}
\newcommand{\prf}{\noindent{\bf Proof.} }
%\newcommand{\prfsk}{\noindent{\bf Eléments de preuve.} }
\newcommand{\eprf}{\bbox}
\newcommand{\bbox}{\vrule height7pt width4pt depth1pt}


%% Blbio
%\newcites{s}{Travaux personnels}
%\newcites{v}{Autres travaux}
%% bibtex s.aux

%% Newcommand
\newcounter{Question}
\newcommand{\question}[1]{\addtocounter{Question}{1} \vspace{0.2cm} \noindent {\it {\bf
(Q\arabic{Question})} #1} \vspace{0.2cm}}

\newcommand{\note}[1]{\vspace{0.1cm}\hspace{-2cm} \noindent {\it {\bf
Note} #1} \vspace{0.1cm}}

\newcommand{\chapterToc}[1]{\chapter*{\numberline{} #1} \addcontentsline{toc}{chapter}{#1} \markboth{#1}{}}
\newcommand{\sectionToc}[1]{\section*{#1} \addcontentsline{toc}{section}{#1} \markboth{#1}{}}
\newcommand{\subsectionToc}[1]{\subsection*{#1} \addcontentsline{toc}{subsection}{#1} \markboth{#1}{}}

%%%% probleme %%%
\newcommand{\SAT}{{\sc Sat}}
\newcommand{\kSAT}{$k$-{\sc Sat}}
\newcommand{\kprimSAT}{$k'$-{\sc Sat}}
\newcommand{\troisSAT}{$3$-{\sc Sat}}
\newcommand{\MinSAT}{{\sc Min SAT}}
\newcommand{\MaxSAT}{{\sc Max SAT}}
\newcommand{\MaxtroisSAT}{{\sc Max 3-SAT}}
\newcommand{\MaxkSAT}{{\sc Max} $k$-{\sc Sat}}
\newcommand{\MinkSAT}{{\sc Min} $k$-{\sc Sat}}
\newcommand{\is}{{\sc Max Independent Set}}
\newcommand{\ds}{{\sc Min Dominating Set}}
\newcommand{\ids}{{\sc Min Independent Dominating Set}}
\newcommand{\vc}{{\sc Min Vertex Cover}}
\newcommand{\cvc}{{\sc Min Connected Vertex Cover}}
\newcommand{\scv}{{\sc Min Set Cover}}
\newcommand{\eds}{{\sc Min Edge Dominating Set}}
\newcommand{\bw}{{\sc Min Bandwidth}}
\newcommand{\uc}{{\sc Max Unused Colors}}
\newcommand{\edc}{{\sc Existing Dominating Clique}}
\newcommand{\mdc}{{\sc Min Dominating Clique}}
\newcommand{\dc}{{\sc Dominating Clique}}
\newcommand{\madc}{{\sc Max Dominating Clique}}
\newcommand{\tsp}{{\sc Min Traveling Salesman}}
\newcommand{\fes}{{\sc Min Feedback Edge Set}}
\newcommand{\colo}{{\sc Min Coloring}}
\newcommand{\troiscolo}{3-{\sc Coloring}}
\newcommand{\st}{{\sc Min Steiner Tree}}
\newcommand{\cd}{{\sc Capacitated Domination}}
\newcommand{\tb}{{\sc Topological Bandwidth}} %% voir \citev{Marx08}
\newcommand{\troishs}{{\sc 3-Hitting Set}}
\newcommand{\hset}{{\sc Hitting Set}}
\newcommand{\pvc}{{\sc Partial Vertex Cover}} %% voir \citev{Marx08}
%%
\newcommand{\maxkcover}{{\sc Max} $k$-{\sc Cover}} %% comme un set cover mais il
% faut trouver les k ensembles qui couvrent le plus d'elements.
\newcommand{\alex}[2]{\textcolor{red}{#1}}


%%%% opti %%%%
\newcommand{\opt}{{\it opt}}

%%%% classes %%%
\newcommand{\np}{{\it NP}}
\newcommand{\fpt}{{\it FPT}}
\newcommand{\xp}{{\it XP}}
\newcommand{\p}{{\it P}}
\newcommand{\snp}{{\it SNP}}
\newcommand{\npo}{{\it NPO}}
\newcommand{\wun}{{\it W[1]}}
\newcommand{\wdeux}{{\it W[2]}}
\newcommand{\wi}{{\it W[i]}}
\newcommand{\mun}{{\it M[1]}}
\newcommand{\ppad}{{\it PPAD}}
\newcommand{\pls}{{\it PLS}}

\begin{document}
%\pagenumbering{Roman} \thispagestyle{empty}
\def \titres{\fbox{\parbox[c]{17cm}{\begin{center}
{\bf \LARGE{
Algorithmic Multistage Optimization }}\end{center}}}}

\def \auteurs{{\Large Alexandre Teiller}}

%\def \univ{{\bf {\Large Universitt}}}

\def \direc{Bruno Escoffier, Euripide Bampis}

\def \jury{
{\large
%\begin{center}
\begin{tabular}{ll}
Coordinateur: Bruno Escoffier and Euripide Bampis \\vspace{0.2cm}\\
\end{tabular}}
}

%\vspace{-4cm}


%\vspace{-3.5cm}

%\begin{figure}[r]
%\includegraphics[width=3cm]{lamsade.eps}
%\end{figure}
\begin{center}




    %\univ

    \vspace{0.3cm}

   % \ufr

    \vspace{3cm}
%     \begin{tabular}{ll}
%    \includegraphics[width=0.10\textwidth]{lamsade} & %
%    \hspace{5cm} uioifd%\includegraphics[clip,height=1cm]{numero} %
%    \end{tabular}
%%
%\begin{figure}[h]
%\begin{center}
%\includegraphics[height=3cm]{logos.eps}
%\end{center}
%\end{figure}
    {\Large {\it  }}

    \vspace{1cm}

    \titres

    \vspace{1cm}

    {\large{\it by}}

\vspace{0.6cm}

    \auteurs

    \vspace{0.8cm}



    \vspace{0.6cm}



\end{center}

    \vspace{1.5cm}

    %\jury aa










\tableofcontents



\chapterToc{Introduction}
\chapter{Optimization with temporal aspects, a state of the art}



In a classical optimization problem, given an instance, one is asked to find a feasible solution optimizing an objective function. The feasibility of a solution is defined by a set of constraints applied to, depending on the nature of the problem, nodes, edges, precedence and so on for graphs, objects for packing problems...\\ A vast amount of optimization problems are known to be NP-hard (see \cite{gj} for a definition of NP-hardness), i.e not polynomially solvable and the complexity theory literature is based upon a central hypothesis, P$\ne$NP, stating that no polynomial algorithm can solved an NP-hard problem. The hardness of those problems make real world applications and implementations really difficult or even impossible. It is then naturally that about 30 years ago approximation algorithms were introduced. Those algorithms give some solutions in reasonable time, more precisely in polynomial time, even if they are not optimal. The quality of a solution outputed by such an algorithm is defined by a ratio, comparing its solution to the optimal solution. In most of the cases, this ratio consists of a constant multiplicative factor, inferior to $1$ for maximization problems and superior to $1$ for minimization problems, guaranteed or not. \\
In parallel of the development of the approximation approach, the temporal approach was elaborated. The idea leading to its introduction was motivated by the same concern, being able to emulate real world problems and solve them, optimally or not. Indeed, we present for the multistage framework in the next section some examples where a temporal approach is needed. In contrast of the fairly recent multistage framework, a lot of different temporal approaches have been developed, most of them since the early 1980's, responding to different applications and needs. \\
We will first develop the multistage optimization, main topic of the thesis, illustrate it with an example and present the actual state of the art of the framework. \\
We will then focus on a few other optimization frameworks with evolving data, being extensively studied and/or sharing some properties with the multistage one. 
\section{Multistage optimization}
\subsection{Introduction and definition of the multistage framework}
In the multistage framework, instead of finding a feasible solution optimizing the problem's objective function, given a time horizon and a set of instances, one for each time step, one is asked to find a set of feasible solutions, one for each time step, optimizing the objective function.

First, let us illustrate this approach with an example. Consider a company owning a set $N=\{u_1,\ldots,u_n\}$ of production units. Each unit can be used or not; if $u_i$ is used, it spends an amount $w_i$ of a given resource (energy, raw material,...), and a generates a profit $p_i$. Given a bound $W$ on the global amount of available resources, the static {\sc Knapsack Problem} aims at determining a feasible solution that specifies the chosen units in order to maximize the total profit under the constraint that the total amount of the resource does not exceed the bound of $W$.

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\begin{tabular}{|l|c|c|r|}
  \hline
   &$u_1$&$u_2$&$u_3$ \\
  \hline
 $w_{i}$ & $1$ & $1$ & $2$\\
    \hline
  $p_{i} $& $3$ & $1$ & $7$\\
  \hline
  $W$ & \multicolumn{2}{c}{\text{   }2} &\\
  \hline
\end{tabular}
\end{subfigure}
\begin{subfigure}[b]{0.4\textwidth}
\begin{tabular}{|l|c|c|r|}
  \hline
   &$u_1$&$u_2$&$u_3$ \\
  \hline
 $w_{i}$ & $1$ & $2$ & $3$\\
    \hline
  $p_{i} $& $2$ & $5$ & $5$\\
  \hline
   $W$ & \multicolumn{2}{c}{\text{     }3} &\\
  \hline
\end{tabular}
\end{subfigure}
\caption{Two instances of the {\sc Knapsack} problem}
\label{statickp}
\end{figure}

Two distinct instances of the {\sc Knapsack} problem are presented in the Figure \ref{statickp}. To get the optimal solution, one has to take in the left instance the production unit $u_3$, obtaining a profit of $7$ and using all the resources, called also capacity of the knapsack, i.e $2$. Otherwise, the profit would be lower or the amount $w_i$ of resources would exceed the global available resources. In the right instance, one has to take the units $u_1$ and $u_2$, obtaining a profit of $7$ and using again all the of the resources, i.e $3$.\\

In a temporal setting and more precisely in the multistage setting, a company would have to decide a production plan over a time horizon $t=1,2,\ldots, T$, of, let us say, $T$ days. The company here needs to decide a production plan for each day of the time time horizon, given that data (such as prices, level of resources,...) usually change over time. This a typical situation, for instance, in energy production planning (like electricity production, where units can be nuclear reactors, wind or water turbines,...), or in data centers (where units are machines and the resource corresponds to the available energy). Moreover, in these examples, there is and extra cost to turn ON or OFF a unit like in the case of turning ON/OFF a reactor in electricity production (\cite{rottner2018combinatorial}), or a machine in a data center (\cite{DBLP:conf/spaa/2017}). Obviously, whenever a reactor is in the ON or OFF state, it is beneficial to maintain it at the same state for several consecutive time steps, in order to avoid the overhead costs of states changes (even if it is important to note that the problem in real situations is much more complicated). Therefore, the design of a production plan over a given time horizon has to take into account both the profits generated each day from the operation of the chosen units, as well as the potential \textit{transition profits} from maintaining a unit at the same state for two consecutive days. Thus, in the {\sc Multistage} framework, instead of having only an instance of a problem and seeking a feasible solution optimizing its objective function, we have a sequence of instances of a problem, one for each time step and one is asked to seek a sequence of feasible solutions, one for each time step, reaching a trade-off between the optimality of the solutions and the stability of consecutive solutions.\\
The problem can be formalized as follows. We have a given time horizon $t=1,2,\ldots,T$, and a sequence of knapsack instances $I_1, I_2, \ldots,I_T$, one for each time step, defined on a set of $n$ productions units, also called objects in the {\sc Knapsack} problem. In every time step $t$ we have to choose a feasible knapsack $S_t$ of $I_t$, which gives a \textit{knapsack profit}. Taking into account transitions costs, we measure the stability/similarity of two consecutive solutions $S_t$ and $S_{t+1}$ by identifying the objects for which the decision, to be picked or not, remains the same in $S_t$ and $S_{t+1}$, giving a \textit{transition profit}. We are asked to produce a sequence of solutions $S_1, S_2, \ldots, S_T$ so that the total \textit{knapsack profit} plus the overall \textit{transition profit} is maximized.\\
There are a lot of other applications where it is beneficial to use a multistage framework. One of them is the {\sc facility location} problem, which we will develop later in this section. Another one is a musical application called the target-based computer-assisted orchestration. We will focus on this latter application in details in the last chapter of the document.\\

Let us now look at the example of Figure \ref{statickp} and consider both instances as a sequence of instances of a {\sc Multistage knapsack} problem with two time steps, the left instance being the instance at the time step $1$ and the right instance the one at the time step $2$. In order to compute a \textit{transition profit}, we need to introduce the notion of the bonus. Let us say that for this example, for each object, one gets a bonus $B=1$ if the object is taken or not taken for two consecutive time steps, i.e if the decision remains the same between time steps $t$ and $t+1$. Thus, the global \textit{transition profit} is equal to $B$ times the total number of decisions that remain the same between two consecutive time steps. For instance, if we take the objects of the static optimal solution, i.e object $u_3$ for the first time step and objects $u_1$ and $u_2$ for the second time step, the \textit{knapsack profit} is equal to $14$, $7$ at both time steps, but the value of the \textit{transition profit} is equal to $0$, none of the decisions remain the same, the object $u_1$ is taken only at time step $1$ whereas the objects $u_2$ and $u_3$ are taken only at the second time step, so we have a the global reward equal to $14$. The optimal solution consists of taking only the object $u_3$ at both time steps, getting a \textit{knapsack profit} equal to $7+5=12$ and all the \textit{transition profit}, as object $u_1$ and $u_2$ are not taken at both time steps and $u_3$ is taken at $t=1$ and $t=2$, i.e $3B = 3$ ; the global
reward is equal to $12+3=15$.\\

The example introduces the {\sc Knapsack} problem in its multistage configuration. This problem is the main subject of the second chapter where we will develop its particularities and properties.\\

Let us now give a formal definition of an optimization problem in its multistage version. 
\begin{definition}{\emph{(Multistage Optimization problem).}} In a Multistage Optimization problem $\cal P$, we are given
\begin{itemize}
\item a number of steps $T \in \mathbb{N}$, a set $N$ of $n$ objects;
\item for any $t \in T$, an instance $I_t$ of the optimization problem. We will denote:
\begin{itemize}
\item $p_{t}$ the objective (profit/cost for resp. maximization/minimization problems) function at time $t$
\item $\mathcal{F}_t\in 2^N$ the set of feasible solutions at time $t$
\end{itemize} 
%\item For each $t$: $C_t$ the capacity of knapsack at time $t$
\item $S_t$ a solution at a time step $t \in T$
\item $b(S_t,S_{t+1})$ the transition (bonus/cost for resp. maximization/minimization problems) function between two solutions at consecutive time steps 
\item the value of a solution sequence $\mathcal{S}=(S_1,\dots,S_T)$ is $$f(\mathcal{S})=\sum_{t=1}^T p_t(S_t) + \sum_{t=1}^{T-1} b(S_t,S_{t+1})$$
We will use the term {\it profit}/cost for $ p_t(S_t)$ for resp. maximization/minimization problems, transition {\it bonus}/cost for the transition bonus/transition cost $b(S_t,S_{t+1})$ for resp. maximization/minimization problems, and {\it value} of a solution $\mathcal{S}$ for $f(\mathcal{S})$;
\item the goal is to determine a solution sequence of maximum/minimum value for resp. maximization/minimization problems. 
\end{itemize}



\end{definition}

The definition presented above is of the few possible ways to define a problem in a multistage version.\\

Indeed, here the global objective function consists of the sum of the profit/cost function and the transition bonus/cost.\\ This definition is quite arbitrary but seemed relevant for the problems encountered during the thesis. Moreover, it follows the original definition of the multistage framework presented in \cite{Gupta} and in \cite{Eisenstat}. It is in fact possible to define the objective function this way when one is able to compare the profit/cost function value and transition bonus/cost function value. For example, it is possible in the previously introduced applications, energy production planning or in data centers problems, the cost of the production  and turning cost of switching ON/OFF a reactor/server are directly comparable.\\
Another way of defining a global objective function for a problem in its multistage version is with a multi-objective function. Indeed, we will see later in this section that for some problems such as the {\sc vertex cover} problem, a multistage version of a problem was introduced where  
one is asked to minimize a number of selected nodes (the classical {\sc vertex cover} problem objective function) and in the same time to minimize the number of modifications regarding the selected subset of nodes for two consecutive time steps. In some cases it is also relevant to bound the number of changes between two consecutive time steps or even to bound them on the whole time horizon. \\

This latter point on the objective function is one aspect subject to differ between several definition of the framework, depending on the nature of the problem studied. \\
Another aspect is the way data may evolve during the time horizon. There are indeed different possibilities of data evolution.
\begin{definition}
\emph{(Types of data evolution.)}
\begin{itemize}
\item \emph{Static Set of Feasible Solutions (SSFS):}  the structure of feasible solutions remains the same: $\mathcal{F}_t=\mathcal{F}$ for all $t \in T$. On the presented {\sc multistage knapsack} problem example, this would be the case if only the profits change over the time horizon, i.e the weights and capacity stay the same between all time steps and thus a solution feasible at a time step is feasible on the whole time horizon.

\item \emph{General Evolution (GE):}  any modification in the input sequence is possible. Both the profits and the set of feasible solutions may change over time. In this latter model, for the {\sc multistage knapsack problem}, profits, weights of objects and the capacity of the bag may change over time; for maximum independent set edges in the graph may change,\dots   
\end{itemize}
\end{definition}

In the third chapter, we will present some results for a class of problems called the {\sc Multistage Subset Maximization} problems (a formal definition will be given in the corresponding chapter) and study these problems in terms of their different types of data evolution. \\

Then, another key point in the definition of a problem in its multistage version is the definition of the transition bonus/cost (maximization/minimization version respectively) function.\\
There are two natural ways to define the transition bonus/cost in the case where the transition bonus/cost function is part of the objective function. We will see that these two ways of measuring the stability induce some differences in the results one can get. 


\begin{definition}
\emph{(Types of transition bonus/cost.)}
We can define the transition bonus/cost as:
\begin{itemize}
    \item \emph{Intersection Bonus/Cost:}  in this case the bonus/cost is proportional to the number of objects in the solution at time $t$ that remain in it at time $t+1$. In the previous example, the value of the bonus would be inferior, indeed we would get a bonus only for the object taken at both time steps but not for the objects not taken at both time steps.
    \item \emph{Hamming Bonus/Cost:} here we get the bonus/cost for each object for which the decision (to be in the solution or not) is the same between time steps $t$ and $t+1$. In other words, the bonus/cost is proportional to $|N|$ minus the number of modifications (Hamming distance) in the solutions. The \emph{Hamming Bonus} was presented previously in the {\sc multistage knapsack} problem example where we got some bonus for both objects taken and not taken at both time steps.
\end{itemize}
\end{definition}

In the case where the global objective function is a Multiple-criteria function, another way of defining the bonus/cost is possible, as said previously one can be asked to bound the number of changes made between two time steps in its decision or even regarding the whole time period.\\

Finally, in order to go further in the development of the multistage framework and present the current state of the art of the multistage framework, we need to present different temporal settings on the knowledge of the data over the time horizon. Three settings are widely known and studied in the literature:
\begin{enumerate}
    \item the \emph{off-line} setting: one has a complete knowledge of the instance over the time horizon (this was the case of the example of Figure \ref{statickp} where we know the whole sequence of instances of the {\sc Multistage Knapsack} problem, it would the case for the electricity planning problem where one is asked to find a solution given a predicted fixed data set, a musical application will be developed in the fourth chapter in this setting when one has a given data set over a time horizon)
    \item the \emph{on-line} setting: at a time step $t$, one only knows the data for today, i.e we have no information regarding the instances at time steps $t+1,\ldots,T$. (another definition where one has also the knowledge of the instance at time $t+1$ is present in the literature). In our definition, we also assume that we know the number $T$ of time steps of the time horizon (another version also exists where this latter point is not known). The \emph{on-line} setting will be develop later in the chapter as it is a extensively studied case of temporal optimization.
    \item the \emph{k-lookahead} setting: at a time step $t$, one knows the data for today and the next $k$ days. This setting is tightly linked to the \emph{on-line} case as it is often used when no results can be obtained in the \emph{on-line} case. In our definition, we again assume that one knows the total number of time steps $T$ of the time horizon. (As in the \emph{on-line} setting, different versions regarding the knowledge of either the time step $t+1,\ldots,k$ and $T$ exist in the literature).
\end{enumerate}

The third chapter deals with {\sc Multistage Subset Maximization} problems in the \emph{on-line} and \emph{k-lookahead} settings, the possible different types of data evolution and transition bonus functions. 

\subsection{State of the art}

In this section, we will cover the current state of the art of the multistage framework. To do so and for the sake of clarity, we will present it problem by problem. We will give a definition of the problem, develop their approaches and current results.\\
The multistage framework defined formally in the previous section follows the direction presented fairly recently by \cite{Gupta} and \cite{Eisenstat} who covered different problems.

\subsubsection{Matching and Perfect Matching problems}
In the static {\sc matching} problem, given a graph, we need to find a set of edges with no vertices in common. A {\sc matching} is called a {\sc perfect matching} if all vertices of a graph are in the set of the selected edges.\\ 
In its multistage version, the perfection version of the problem is called the {\sc perfect matching maintenance} and consists of keeping the perfect macthing property over the time horizon, i.e at each time step, while the cost function and cost value for adding new elements is subject to change during the time horizon.\\

In \cite{Gupta}, they showed that the {\sc perfect matching maintenance} problem becomes surprisingly inapproximable, even in the \emph{off-line} case. To do so, they did a reduction from the {\sc 3-colorability} problem, known to be NP-hard in graph with bounded degrees, and more precisely with maximum degree 4 (\cite{guruswami2004hardness}). This last negative result is the first observation of the hardness induced by the multistage framework. Indeed, the majority of the problems studied for now and considered easy, i.e polynomial solvable or easily approximable, in their static form become really hard in this framework, even for limited restricted instances, in the \emph{off-line} case and for a small number of time steps.\\

The negative result on the {\sc perfect matching maintenance} was improved a few years later in \cite{bampis2018multistage}. Indeed, in \cite{Gupta}, it was shown that the problem was innaproximable for instances with as least $8$ time steps but the question for less time steps and for specific instances such as bipartite graph was left open. \cite{bampis2018multistage} addressed this open question and proved that the problem is hard to approximate. Then, they showed other negative results. Even the metric version of the problem where the triangle inequalities are satisfied, called {\sc minimum multistage perfect matching}, is APX-hard i.e does not have a PTAS (a formal definition of a PTAS is given in the second chapter). However, in the case where the number of time steps it equal to $2$ or $3$, they presented a constant approximation ratio. Finally, they also showed that the problem in its maximization version, with the complementary objective function, was also APX-hard even though it has a constant approximation ratio. \\


Very recently, in \cite{chimani2020approximating}, the authors looked again at the {\sc multistage matching} problem and a variant where the number of overall modifications are as small as possible. They improved the results presented in \cite{bampis2018multistage} by showing the NP-hardness of the problem in an even more restricted case than the one presented in \cite{bampis2018multistage}. They also presented a new approximation algorithm that does not require the restrictions needed before.

\subsubsection{Facility Location problem}

In the {\sc facility location }problem, one is asked, given a set of clients and facilities, to find the best connections of clients to facilities such that the tradeoff between, here a sum, of two objectives is minimum. The first objective is the distance objective, corresponding to the sum of the clients to facilities, each client has to be connected to a facility and as close as possible to their facilities. The second is an opening cost paid for each opened facility. Thus one has to select the least amount of facilities to open such that the sum of distances between clients and facilities and paid opening costs is minimum.\\
The multistage version of the problem, called the {\sc Dynamic Facility Location problem}, shares the same two objectives with the static version. However, it has a third objective, also summed with the other two objectives, called the non-negative client switching cost. Indeed, a cost is paid for switching clients between different facilities between two consecutive time steps. This last function measures the stability of the solution during the time horizon.\\

For both the static and the multistage versions of the problem, there exists a variant in the definition of the opening cost per facility. Indeed, one has to pay either a \textit{fixed} opening cost to open a facility, the facility remains open for the whole time horizon, either a \textit{hourly} opening cost, paying for each facility opened at each time step.\\

In \cite{Eisenstat}, they addressed the {\sc facility location }problem in the multistage framework. The application underlying the study of this problem is another example of a possible application and need of stability in the decisions making among a time horizon. In our era, a huge amount of data are collected on social networks and their studies are more and more important. These networks quickly evolve in time and it is thus important to be able to analyze such data in a dynamic environment. Even though the {\sc facility location} problem have been widely studied in temporal settings, the notion of stability was not really looked at. Taking into account this stability, here represented by clients moving or not between a set of facilities gives the possibility to understand better clients behaviour and highlight the impact of clients moving through different facilities. It thus offers better results in realistic situations giving stable group partition of the network. The authors proposed a logarithmic approximation for the problem and gave a matching inapproximability result in restricted instances respecting the triangle inequalities, with only one client, two possible positions and a fixed opening cost. These instances admit a constant approximation ratio in the static framework. \\

In \cite{an2017dynamic}, the authors treated the left open question in \cite{Eisenstat} and presented a constant factor approximation algorithm using LP-rounding techniques for the version of the problem where opening cost are paid \textit{hourly}.

\subsubsection{Spanning Tree problem}

In the {\sc spanning tree} problem, one is asked to find a tree $A$ in a directed graph such that all vertices of the graph are connected and that the total edge weight of the selected path is minimum.\\
In its multistage version, given a set of instances of a directed graph and a number $T$ of time steps, we need to find a subset of spanning trees $A_t $ for $t \in T$, one for each time step, such that it is minimal. For each time step, we pay the price for the tree, as in the classical static version of the problem and also $|A_t \setminus A_{t-1} |$ for the modification of edges between two consecutive time steps. \\


In \cite{Gupta}, they studied the {\sc multistage matroid maintenance} problem, problem with some costs induced by changing decisions at some time steps on some edges and with an application quite similar to the one presented in our example. As a special case, the problem can be seen as a natural multistage version of the {\sc Spanning tree} problem.  They looked at both the \emph{on-line} and \emph{off-line} versions of the problem and gave logarithmic approximation algorithms in both cases using some LP-rounding, randomized algorithms and matroid techniques (see \cite{vazirani2013approximation} for details on approximation algorithms). They improved a result from \cite{buchbinder2012unified} and \cite{buchbinder2014competitive} who looked at a fractional version and later a more general version of the problem. 





\subsubsection{List Update problem}
In the {\sc list update} problem, given a set of items with values corresponding to their distances to the head of a track, a set of requests (these requests can be in the \textit{off-line} or in the \textit{on-line} settings) and a constraint on a fixed position for each item at each time step, one has to give for each item an affection to a position in the track for the whole time horizon minimizing the cost of all the requests. \\
In a multistage version of a closed variant of the problem, called the {\sc dynamic minimum linear arrangement} problem, there is no constraint on the position of an item at the beginning of each time step and one has to pay a cost for moving an item from one position to another between two time steps, measuring this way the stability of the solution.\\

In \cite{olver2018itinerant}, the authors studied this multistage problem in both the \emph{off-line} setting, presenting a polylogarithmic approximation algorithm, and the  \emph{on-line} setting, giving a logarithmic lower bound on the competitive ratio of any randomized algorithm against an oblivious adversary. 

\subsubsection{Discrete minimization problems}
Here we won't present the problem in its static and its multistage version as the results concern a lot of different discrete minimization problems. The idea is to highlight the possibility of using some LP-rounding techniques in a multistage framework.\\

Indeed, last year, \cite{bampis2019lp} studied a wide variety of discrete minimization problems in a multistage framework. They presented some surprisingly positive results. Indeed, for some minimization integer programming problems refereed to as \textit{monotone} problems, polynomially solvable in their static version, such as the {\sc min cut} problem, they proved that the problems remain polynomially solvable in their multistage version. These results are surprising knowing that problems in the multistage framework presented before become much harder that their static version, problems solvable by a polynomial algorithm become NP-hard. \\
They also showed that a known result in the static framework assuring both problems having the semi-integrality property and the {\sc vertex cover} problem are 2-approximable holds in the multistage framework. Finally they introduced a new rounding technique with two-threshold designed specially for multistage problems and proved some constant approximation ratio for multistage version of the {\sc Prize-Collecting Steiner Tree} problem and the {\sc Prize-Collecting Traveling Salesman} problem. 



\subsubsection{Santa Claus problem}
In the {\sc santa claus} problem, also called {\sc max min fair allocation} problem, given a set of resources and agents, one is asked to find an allocation of resources to agents such that the value of the \textit{worts-off} agent, i.e with the minimal subset of resources, is maximum. \\
The problem in the multistage framework, called the {\sc over-time max min fair allocation} problem, in addition of sharing the same objective as its static version, has a \textit{transition revenue} evaluating the stability of solutions between two consecutive time steps. Indeed, one has a bonus for keeping the same decision over the time horizion, i.e here corresponding to resources remaining on the a same agent for two consecutive time steps. The global objective function sums these two objectives.\\

In \cite{bampis2018fair}, the authors addressed this problem. They studied the problem in the \emph{off-line}, \emph{on-line} and \emph{1-lookahead} settings and for different kind of evolving instances. The study of different kind of evolving instances is crucial in temporal optimization and will be developed in the third chapter. They showed that in its \emph{off-line} version, the problem is much harder than its static version. It becomes NP-hard even for simple instances without restriction whereas these instances are trivially solved in the static version of the problem (instances where the static set of feasible solutions over the time horizon, i.e in this case instances where the set of resources and agents are the same during the whole time horizon and every resource can be allocated to any agent). Regarding the \emph{on-line} version of the problem, they proposed a constant competitive ratio for instances without restriction using an approximation algorithm for the static case as a subroutine. For instances where the feasible set of solution can change between different time steps, they showed that the problem has no bounded competitive ratio in the \emph{on-line} setting. Finally, they looked at the \emph{1-lookahead} version of the problem, in the same instance evolving setting and proposed a constant approximation algorithm using again a approximation algorithm for the static case as a subroutine. \\

The {\sc over-time max min fair allocation} problem is the only multistage problem presented in the literature up to our knowledge addressing a multistage maximization problem, all presented multistage problems are minimizing problems. We will develop in the second and third chapter of this document a study on a large class of multistage maximization problems called the {\sc Multistage Subset Maximization} problems and a special \textit{off-line} study on the {\sc multistage knapsack problem}.


\subsubsection{Parameterized multistage studies}
Let us now develop the different definition on the global objective function of a multistage problem presented in the previous section. In the following problems the global objective function is a multi-objective function. Indeed, whereas the problems presented before share the notion of \textit{transition profit} or \textit{transition cost}, ensuring that the solution does not change too much over the time horizon, here the stability is a represented by a bound over the number of changes in a decision one can make between two time steps. Let us illustrate this function more precisely with the {\sc vertex cover} problem.

\subsubsection{Vertex Cover problem}
In the classical static version of the {\sc vertex cover} problem, given a undirected graph, one is ask to find the smallest subset of vertices such that all edges contain at least one endpoint in the cover.\\
In the multistage version of the {\sc vertex cover} problem, one is asked to find a small subset of vertices covering the edges of a temporal graph, i.e a subset of vertices at each time step in a set of graph with a fixed set of vertices but with a set of edges evolving during the time horizon, such that the number of changes between two solutions of two consecutive time steps does not exceed a given parameter.\\
A set of graph, with either the set of vertices or the set of edges changing over a time horizon is called a temporal graph. It is very well studied in the temporal optimization literature and will be presented more into details further in this chapter.\\


In \cite{fluschnik2019multistage}, a multistage version of the {\sc Vertex cover} problem is studied. The {\sc multistage vertex cover} problem differs a bit from the other multistage problems we presented before. They showed that in the case where the number of time steps of the problem can be anything, i.e not a constant, the {\sc Multistage vertex cover} is NP-hard even for one edge instances at every time step. Note that these instances are trivial in the static case. They also proved that the problem becomes NP-hard even for two time steps and on restricted instances where the graph of the first time step is a path and the one of the second time step is a tree. Then, they showed that if the parameter corresponding to the number of changes allowed between two time steps is smaller than two times the size of the cover, the problem is not fixed-parameter tractable (i.e W[1]-hard). The problem appears to be FPT otherwise (see \cite{downey2012parameterized} for a survey on parameterized complexity). \\

In \cite{heeger2019multistage}, the authors also looked at the multistage framework in the parametrized version, with a constraint on the number of allowed modifications in the solutions selected in two consecutive time steps. A contrario to the one presented before where the constraint was local, they introduced a global constraint with a bound on the number total of modifications. They introduced the {\sc global multistage vertex cover} problem and proved that it is FPT by the upperbound of the size of the solution and by the number of time steps but W[1]-hard parametrized by the upperbound only. \\
The authors also addressed a global multistage version of the {\sc min cut} problem giving some W[1]-harndess results. They finally highlighted that some polynomial-time solvable problems are harder, computationnaly speaking, in a global multistage framework than global multistage NP-hard problem. 

\subsubsection{s-t Path problem}
In the {\sc s-t Path} problem, given a directed weighted graph containing two nodes $s$ and $t$, one is asked to find the shortest path between $s$ and $t$.\\
In the multistage version of the problem, the {\sc multistage s-t path problem}, given a temporal graph with the same vertex set but with changing edges over the time horizon, one is asked to find a minimum path between $s$ and $t$ in the temporal graph so that it is as stable as possible. The stability here is represented by a bound on the number of authorized modifications between two time steps, either on the vertex or on the edges. 

In \cite{stpath}, the authors proved in this paper 
that for very restricted instances with only two time steps and the maximal degree of any vertex of the temporal graph less or equal to 4, the problem becomes NP-hard (for both variants of the problem). They also looked at the parameterized complexity and showed some inapproximability results, i.e W[1]-hardness, when the parameter is the size of the solution returned. They were also the first to addressed the notion of dissimilarity, in contrast of the similarity, stability, of two consecutive solutions normally studied. In this variant, they presented this time a FPT algorithm in the size of the solution returned. 

\subsubsection{Committee Election problem}
In the {\sc Committee Election} problem, given a set of agents, a set of candidates and a voting function, called voting profiles, one is asked to find the smallest committee such that it has a sufficient number of approvals.\\
Two variant of the {\sc Multistage Committee Election} exist. In the first one, given a set of agents, a set of candidates, a sequence of voting profiles over a time horizon and an integer $k$, one is asked to find a sequence of small committees, one for each time step, such that the number of approvals is sufficiently large and that the size of the symmetric difference of two consecutive committees in the time horizon is lower than k. This version is called the {\sc Conservative Multistage Plurality Voting} problem.\\
In the other variant called the {\sc Revolutionary Multistage Plurality Voting} problem, the problem is the same as the one presented above but this time the symmetric difference of two consecutive committees in the time horizon has to be greater than the fixed given integer parameter.\\

In \cite{multicomm}, the authors looked at both variants of the multistage problem. They showed NP-hardness of both problems where the number of agents is fixed and gave some parameterized complexity results. Indeed, they showed that again both problems are W[1]-hard from a certain number of stages, being FPT otherwise. At last, they presented a polynomial algorithm for the revolutionary problem, while the conservative variant remains NP-hard, when the fixed parameter on the symmetric difference between two consecutive time steps is a constant. 

\subsubsection{Current stage of the multistage framework}

We presented the current state of the multistage framework. This setting is fairly recent but more and more studied with a lot of publications within the last few years. Indeed, authors keep improving the results and observations introduced in 2014 by \cite{Gupta} and \cite{Eisenstat}. Some surprising properties are being highlighted such as strong negative results (NP-hardness, inapproximability, W[1]-hardness) for very restricted instances (even sometimes for trivial instances in the static framework) and only a few time steps, problems polynomially solvable in a static version becoming harder than NP-hard problem, and also a few positive results, some problems keeping their static version properties in the multistage framework. The community looked at a few different settings regarding the evolution of the instances, the bonus/cost representing the stability, the knowledge over the time horizon, the parametrized version of the framework. Some of them will be developed later in the second and third chapter. The framework have still a lot of open questions and settings to be looked at. \\
The vast majority of the problems studied in the framework are minimization multistage problems. This one was of the reason that motivated us to focus ourselves on maximization problems. As said previously, we studied a large class of maximization problems in different settings and this will be detailed in the second and third chapter of this document.


\alex{mettre a jour biblio de l'etat de l'art avec dblp}\\
\section{Some other approaches}

As said in the introduction of this chapter, optimization in dynamic environment gathers a wide variety of researches branches. They were, for most of them, developed in the last 30 years in parallel of the approximation approach, feeding one another continuously.\\
We will develop here different branches of researches taking into account optimization problems with evolving data sets. We will see that some of them are very studied in the literature and that some others are closely linked to the multistage framework. For each temporal approach presented, we will focus on the similarities and differences from the multistage framework. 

\subsectionToc{Reoptimization}
We will first develop the reoptimization paradigm. For a more complete survey on reoptimization, see (\cite{boria2011survey}) from which we were strongly inspired to design this section.  The notion was introduced in \cite{Schaffter97} where a scheduling problem was addressed and later developed in \cite{archetti2003reoptimizing} in which the authors addressed the {\sc travelling salesman} problem, a very well know NP-hard problem, and considered two distinct steps. In a first step, an algorithm gives an optimal or approximate solution for a NP-hard problem in a static framework. The reoptimization focuses on the second step where the instance is perturbed, i.e vertex or edge deletions for graph problems, changing values for numerical problems$\ldots$ one is then asked to maintain the optimality/approximation ratio of the solution. Note that the perturbation in the reoptimization context is small, i.e only one vertex or edge is deleted for a graph problem$\ldots$ \\
This two steps give direct property for problem in their reoptimization version. Indeed, the result of NP-hardness of a problem holds in the reoptimization framework, otherwise one could solve any NP-hard problem using reoptimization algorithms and starting from an empty instance. However, some problems are known to be hard to approximate in their static version and becomes APX or even admits a PTAS in the reoptimization framework (it is the case for example for the {\sc max independ set} problem). This is why the majority of the results presented in this framework concern approximation algorithms. More generally, two kinds of results can be achieved for NP-hard problems in their reoptimization version:
\begin{itemize}
    \item the reoptimization algorithm gives with a better running time  an optimal or approximate solution as good as the solutions given by the best known algorithm for the problem in its staic version 
    \item the reoptimization algorithm gives in polynomial time a better approximation ratio than the best one known for the problem in its classic static version
\end{itemize}

A reoptimization algorithm is thus closely linked to the multistage framework, as it has to maintain a certain quality in the solution. To do so, one has to look at the solution already found and try to adapt this one for the new instance. This often implies keeping a huge part of the solution in the new instance and thus keeping the solution stable. The main differences with the multistage framework are:
\begin{itemize}
    \item the instances modifications appear locally and affect only one object or constraint at each time step
    \item one has to use the solution found at the previous time step and to find another solution locally without taking into account in its value the solution value for the previous time step
\end{itemize} 




\begin{ex}
Train scheduling \\
In a train station, an algorithm has to find a distribution over a time period for trains to its platforms, so that the corresponding schedule problem is optimized. It is relevant here to consider spending a lot of computing time in order to output the best possible solution. However, in real world situations, some perturbations and problems can occur, malfunction of a train, breakdown$\ldots$, implying the infeasibility of the presented solution. In this case, considering spending a lot of time to find a new optimal solution from scratch is not pertinent and a simple adaptation of the previous optimal solution would be way more beneficial. Indeed, here one can use some reoptimization algorithm and output a solution in a short amount of time, i.e in polynomial time, based on the previous one.

\end{ex}


\textbf{Fully dynamic and reoptimization algorithms}\\
We will here present the fully dynamic and reoptimization algorithms. A more complete survey on these approaches is presented in \cite{boria2011survey} which our development is based on. At first and before the proper elaboration of the concept of reoptimization, fully dynamic algorithms were studied. Those algorithms mainly focused on some polynomial problem like the {\sc min spanning tree} (\cite{frederickson1985data}) and the {\sc shortest path} problem (\cite{even1985updating}). They were applied on data structures and were designed to maintain the optimality of a solution on instances subject to some perturbations. 

 

A survey on combinatorial optimization in dynamic environments Paschos\\
amortized complexity

\subsectionToc{reoptimization}

book : \\
On the Hardness of Reoptimization Hans-Joachim Böckenhauer\\

On the Tradeoff between Stability and Fit
EDITH COHEN : "Two hugely popular models are metrical task systems, where the goal is to maximize average fit per average change [Borodin et al. 1992] and regret minimization used in decision theory."\\ 


\subsectionToc{online}
optima 54 Susanne Albers\\
regularization\\
competitive ratio\\


Competitive Analysis via Regularization
Niv Buchbinder Shahar Chen Joseph (Seffi) Naor\\

book : \\
Online Algorithms
The State of the Art\\

Online Optimization jaillet \\
\subsectionToc{incremental setting?}
\subsectionToc{online learning}
Buchbinder et al. [14] and Buchbinder, Chen and Naor [13] considered also a multistage model and studied the re- lation between the online learning and competitive analysis frameworks, mostly for fractional optimization problems.\\     
prediction? randomization\\
N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University Press, 2006\\

Unified Algorithms for Online Learning and Competitive Analysis
Niv Buchbinder
\\

\subsectionToc{Online stochastic combinatorial optimization}



\subsectionToc{dynamic parameterized complexity}
Reoptimization of Parameterized Problems Hans-Joachim Bockenhauer\\

\subsectionToc{temporal/dynamic graphs}

Dynamic Graph Algorithms Giuseppe F. Italiano\\
when a solution is taken the instance, edges or vertices change \\
DATA STRUCTURES FOR ON-LINE UPDATING OF
MINIMUM SPANNING TREES, WITH APPLICATIONS*\\

\alex{temporal spirachis, existence de chemins, flow}\\

\chapter{Multistage Knapsack Problem}

define PTAS
\chapter{Online Multistage Subset Maximisation Problems}
Let us now define formally a class of problems, the Subset Maximisation Problems and then its multistage version.

\begin{definition}

\emph{(Subset Maximization Problems.)} A Subset Maximization problem $\cal P$ is a combinatorial optimization problem whose instances $I=(N,p,\mathcal{F})$ consist of
\begin{itemize}
    \item A ground set $N$;
    \item A set $\mathcal{F}\subseteq 2^N$ of feasible solutions such that $\emptyset\in\mathcal{F}$;
    \item A non-negative weight $p(S)$ for every $S \in \mathcal{F}$.
\end{itemize}
The goal is to find $S^*\in \mathcal{F}$ such that $p(S^*)=\max\{p(S):S\in\mathcal{F}\}$.
\end{definition}
This is a very general class of problems, including the maximization \emph{Subset Selection} problems studied by Pruhs and Woeginger in (\cite{Pruhs}) (they only considered linear objective functions). It contains for instance graph problems where $N$ is the set of vertices (as in any maximization induced subgraph problem verifying some property) or the set of edges (as in  matching problems). It also contains classical set problems (knapsack, maximum 3-dimensional matching,\dots), and more generally 0-1 linear programs (with non negative profits in the objective function).
Given a problem in the previous class, we are interested in its multistage version.
The stability over time of a solution sequence is classically captured by considering a \textit{transition cost} when a modification is made in the solution. Here, dealing with maximization problems, we will consider a transition {\it bonus} $B$ for taking into account the similarity of two consecutive solutions.
In what follows, we will use the term object to denote an element of $N$ (so an object can be a vertex of a graph, or an edge,\dots, depending on the underlying problem). 	%\textcolor{red}{Kevin: were we assuming anywhere now that $\emptyset$ is feasible?}
\begin{definition}
\emph{(Multistage Subset Maximization Problems.)} In a Multistage Subset Maximization problem $\cal P$, we are given
\begin{itemize}
\item a number of steps $T \in \mathbb{N}$, a set $N$ of $n$ objects;
\item for any $t \in T$, an instance $I_t$ of the optimization problem. We will denote:
\begin{itemize}
\item $p_{t}$ the objective (profit) function at time $t$
\item $\mathcal{F}_t\in 2^N$ the set of feasible solutions at time $t$
\end{itemize} 
%\item For each $t$: $C_t$ the capacity of knapsack at time $t$
\item $B \in \mathbb{R^{+}}$ a given \textit{transition profit}. 
\item the value of a solution sequence $\mathcal{S}=(S_1,\dots,S_T)$ is $$f(\mathcal{S})=\sum_{t=1}^T p_t(S_t) + \sum_{t=1}^{T-1} b(S_t,S_{t+1})$$
where $b(S_t,S_{t+1})$ is the transition bonus for the solution between time steps $t$ and $t+1$. We will use the term {\it profit} for $ p_t(S_t)$, {\it bonus} for the transition bonus $b(S_t,S_{t+1})$, and {\it value} of a solution $\mathcal{S}$ for $f(\mathcal{S})$;
\item the goal is to determine a solution sequence of maximum value. 
\end{itemize}
\end{definition}

The definition above defined formally a general class of maximization problems in a multistage setting. It is possible to define in a similar way a general class of multistage minimization problems, the main difference is that in a minimization problem, we don't consider a bonus but a cost and a \textit{transition cost} induced by changing our decisions between two consecutive time steps.

\chapter{Target-based computer-assisted orchestration: a theoretical analysis}
\pagenumbering{arabic}

%\sectionToc{Contenu de ce document}
\bibliographystyle{apalike}
\bibliography{biblio}


\end{document}
