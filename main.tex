\documentclass[a4paper]{book}


%% Mise en page
\addtolength{\hoffset}{-0.8cm} \addtolength{\textwidth}{2.8cm}
\addtolength{\voffset}{-1.4cm} \addtolength{\textheight}{3.3cm}
\addtolength{\evensidemargin}{-1.9cm}

%% Packages
%\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{theorem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage[sectionbib]{natbib}
%\usepackage{multibib}
\usepackage{graphicx}
\usepackage{pstricks}
\usepackage{psfrag}


\usepackage{textpos}
\usepackage{graphicx}
\usepackage{xcolor,colortbl}
\usepackage{pgfgantt}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{xcolor,colortbl}

\definecolor{bleu}{rgb}{0.2,0,0.2}
\definecolor{macouleur}{rgb}{0.5,0.5,0.5}
 \definecolor{greenz}{cmyk}{1.0,0,1.0,0.4}
 \definecolor{purplez}{cmyk}{0.0,1.0,0.0,0.1}

%% Theorem like
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{ex}{Example}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{definition}{Definition}
\newcommand{\prf}{\noindent{\bf Proof.} }
%\newcommand{\prfsk}{\noindent{\bf El√©ments de preuve.} }
\newcommand{\eprf}{\bbox}
\newcommand{\bbox}{\vrule height7pt width4pt depth1pt}


%% Blbio
%\newcites{s}{Travaux personnels}
%\newcites{v}{Autres travaux}
%% bibtex s.aux

%% Newcommand
\newcounter{Question}
\newcommand{\question}[1]{\addtocounter{Question}{1} \vspace{0.2cm} \noindent {\it {\bf
(Q\arabic{Question})} #1} \vspace{0.2cm}}

\newcommand{\note}[1]{\vspace{0.1cm}\hspace{-2cm} \noindent {\it {\bf
Note} #1} \vspace{0.1cm}}

\newcommand{\chapterToc}[1]{\chapter*{\numberline{} #1} \addcontentsline{toc}{chapter}{#1} \markboth{#1}{}}
\newcommand{\sectionToc}[1]{\section*{#1} \addcontentsline{toc}{section}{#1} \markboth{#1}{}}
\newcommand{\subsectionToc}[1]{\subsection*{#1} \addcontentsline{toc}{subsection}{#1} \markboth{#1}{}}

%%%% probleme %%%
\newcommand{\SAT}{{\sc Sat}}
\newcommand{\kSAT}{$k$-{\sc Sat}}
\newcommand{\kprimSAT}{$k'$-{\sc Sat}}
\newcommand{\troisSAT}{$3$-{\sc Sat}}
\newcommand{\MinSAT}{{\sc Min SAT}}
\newcommand{\MaxSAT}{{\sc Max SAT}}
\newcommand{\MaxtroisSAT}{{\sc Max 3-SAT}}
\newcommand{\MaxkSAT}{{\sc Max} $k$-{\sc Sat}}
\newcommand{\MinkSAT}{{\sc Min} $k$-{\sc Sat}}
\newcommand{\is}{{\sc Max Independent Set}}
\newcommand{\ds}{{\sc Min Dominating Set}}
\newcommand{\ids}{{\sc Min Independent Dominating Set}}
\newcommand{\vc}{{\sc Min Vertex Cover}}
\newcommand{\cvc}{{\sc Min Connected Vertex Cover}}
\newcommand{\scv}{{\sc Min Set Cover}}
\newcommand{\eds}{{\sc Min Edge Dominating Set}}
\newcommand{\bw}{{\sc Min Bandwidth}}
\newcommand{\uc}{{\sc Max Unused Colors}}
\newcommand{\edc}{{\sc Existing Dominating Clique}}
\newcommand{\mdc}{{\sc Min Dominating Clique}}
\newcommand{\dc}{{\sc Dominating Clique}}
\newcommand{\madc}{{\sc Max Dominating Clique}}
\newcommand{\tsp}{{\sc Min Traveling Salesman}}
\newcommand{\fes}{{\sc Min Feedback Edge Set}}
\newcommand{\colo}{{\sc Min Coloring}}
\newcommand{\troiscolo}{3-{\sc Coloring}}
\newcommand{\st}{{\sc Min Steiner Tree}}
\newcommand{\cd}{{\sc Capacitated Domination}}
\newcommand{\tb}{{\sc Topological Bandwidth}} %% voir \citev{Marx08}
\newcommand{\troishs}{{\sc 3-Hitting Set}}
\newcommand{\hset}{{\sc Hitting Set}}
\newcommand{\pvc}{{\sc Partial Vertex Cover}} %% voir \citev{Marx08}
%%
\newcommand{\maxkcover}{{\sc Max} $k$-{\sc Cover}} %% comme un set cover mais il
% faut trouver les k ensembles qui couvrent le plus d'elements.
\newcommand{\alex}[2]{\textcolor{red}{#1}}


%%%% opti %%%%
\newcommand{\opt}{{\it opt}}

%%%% classes %%%
\newcommand{\np}{{\it NP}}
\newcommand{\fpt}{{\it FPT}}
\newcommand{\xp}{{\it XP}}
\newcommand{\p}{{\it P}}
\newcommand{\snp}{{\it SNP}}
\newcommand{\npo}{{\it NPO}}
\newcommand{\wun}{{\it W[1]}}
\newcommand{\wdeux}{{\it W[2]}}
\newcommand{\wi}{{\it W[i]}}
\newcommand{\mun}{{\it M[1]}}
\newcommand{\ppad}{{\it PPAD}}
\newcommand{\pls}{{\it PLS}}

\begin{document}
%\pagenumbering{Roman} \thispagestyle{empty}
\def \titres{\fbox{\parbox[c]{17cm}{\begin{center}
{\bf \LARGE{
Algorithmic Multistage Optimization }}\end{center}}}}

\def \auteurs{{\Large Alexandre Teiller}}

%\def \univ{{\bf {\Large Universitt}}}

\def \direc{Bruno Escoffier, Euripide Bampis}

\def \jury{
{\large
%\begin{center}
\begin{tabular}{ll}
Coordinateur: Bruno Escoffier and Euripide Bampis \\vspace{0.2cm}\\
\end{tabular}}
}

%\vspace{-4cm}


%\vspace{-3.5cm}

%\begin{figure}[r]
%\includegraphics[width=3cm]{lamsade.eps}
%\end{figure}
\begin{center}




    %\univ

    \vspace{0.3cm}

   % \ufr

    \vspace{3cm}
%     \begin{tabular}{ll}
%    \includegraphics[width=0.10\textwidth]{lamsade} & %
%    \hspace{5cm} uioifd%\includegraphics[clip,height=1cm]{numero} %
%    \end{tabular}
%%
%\begin{figure}[h]
%\begin{center}
%\includegraphics[height=3cm]{logos.eps}
%\end{center}
%\end{figure}
    {\Large {\it  }}

    \vspace{1cm}

    \titres

    \vspace{1cm}

    {\large{\it by}}

\vspace{0.6cm}

    \auteurs

    \vspace{0.8cm}



    \vspace{0.6cm}



\end{center}

    \vspace{1.5cm}

    %\jury aa










\tableofcontents



\chapterToc{Introduction}
\chapter{Optimization with temporal aspects, a state of the art}



In a classical optimization problem, given an instance, one is asked to find a feasible solution optimizing an objective function. The feasibility of a solution is defined by a set of constraints applied to, depending on the nature of the problem, nodes, edges, precedence and so on for graphs, objects for packing problems...\\ A vast amount of optimization problems are known to be NP-hard (\cite{gj}), i.e not polynomially solvable and the complexity theory literature is based upon a central hypothesis, P$\ne$NP, stating that no polynomial algorithm can solved an NP-hard problem. The hardness of those problems make real world applications and implementations really difficult or even impossible. It is then naturally that about 30 years ago approximation algorithms were introduced. Those algorithms give some solutions in reasonable time, more precisely in polynomial time, even if they are not optimal. The quality of a solution outputed by such an algorithm is defined by a ratio, comparing its solution to the optimal solution. In most of the cases, this ratio consists of a constant multiplicative factor, inferior to $1$ for maximization problems and superior to $1$ for minimization problems, guaranteed or not. \\
In parallel of the development of the approximation approach, the temporal approach was elaborated. The idea leading to its introduction was motivated by the same concern, being able to emulate real world problems and solve them, optimally or not. Indeed, we presented for the multistage framework in the previous section some examples where a temporal approach is needed. In contrast of the fairly recent multistage framework, a lot of different temporal approaches have been developed, most of them since the early 1980's, responding to different applications and needs. \\
We will first develop the multistage optimization, main topic of the thesis, illustrate it with an example and present the actual state of the art of the framework. \\
We will then focus on a few other optimization frameworks with evolving data, being extensively studied and/or sharing some properties with the multistage one. \\
\section{Multistage optimization}
\subsection{Introduction and definition of the multistage framework}
In the multistage framework, instead of finding a feasible solution optimizing the problem's objective function, on a time horizon with some time steps, one is asked given a set of instance, one for each time step, to find a set of feasible solutions, one for each time step, optimizing the objective function.

First, let us illustrate this approach with an example. Consider a company owning a set $N=\{u_1,\ldots,u_n\}$ of production units. Each unit can be used or not; if $u_i$ is used, it spends an amount $w_i$ of a given resource (energy, raw material,...), and a generates a profit $p_i$. Given a bound $W$ on the global amount of available resources, the static {\sc Knapsack Problem} aims at determining a feasible solution that specifies the chosen units in order to maximize the total profit under the constraint that the total amount of the resource does not exceed the bound of $W$.

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\begin{tabular}{|l|c|c|r|}
  \hline
   &$u_1$&$u_2$&$u_3$ \\
  \hline
 $w_{i}$ & $1$ & $1$ & $2$\\
    \hline
  $p_{i} $& $3$ & $1$ & $7$\\
  \hline
  $W$ & \multicolumn{2}{c}{\text{   }2} &\\
  \hline
\end{tabular}
\end{subfigure}
\begin{subfigure}[b]{0.4\textwidth}
\begin{tabular}{|l|c|c|r|}
  \hline
   &$u_1$&$u_2$&$u_3$ \\
  \hline
 $w_{i}$ & $1$ & $2$ & $3$\\
    \hline
  $p_{i} $& $2$ & $5$ & $5$\\
  \hline
   $W$ & \multicolumn{2}{c}{\text{     }3} &\\
  \hline
\end{tabular}
\end{subfigure}
\caption{Two instances of the {\sc Knapsack} problem}
\label{statickp}
\end{figure}

Two distinct instances of the {\sc Knapsack} problem are presented in the Figure \ref{statickp}. To get the optimal solution, one has to take in the left instance the production unit $u_3$, obtaining a profit of $7$ and using all the resources, called also capacity of the knapsack, i.e $2$. Otherwise, the profit would be lower or the amount $w_i$ of resources would exceed the global available resources. In the right instance, one has to take the units $u_1$ and $u_2$, obtaining a profit of $7$ and using again all the of the resources, i.e $3$.\\

In a temporal setting and more precisely in the multistage setting, a company would have to decide a production plan over a time horizon $t=1,2,\ldots, T$, of, let us say, $T$ days. The company here needs to decide a production plan for each day of the time time horizon, given that data (such as prices, level of resources,...) usually change over time. This a typical situation, for instance, in energy production planning (like electricity production, where units can be nuclear reactors, wind or water turbines,...), or in data centers (where units are machines and the resource corresponds to the available energy). Moreover, in these examples, there is and extra cost to turn ON or OFF a unit like in the case of turning ON/OFF a reactor in electricity production (\cite{rottner2018combinatorial}), or a machine in a data center (\cite{DBLP:conf/spaa/2017}). Obviously, whenever a reactor is in the ON or OFF state, it is beneficial to maintain it at the same state for several consecutive time steps, in order to avoid the overhead costs of states changes (even if it is important to note that the problem in real situations is much more complicated). Therefore, the design of a production plan over a given time horizon has to take into account both the profits generated each day from the operation of the chosen units, as well as the potential \textit{transition profits} from maintaining a unit at the same state for two consecutive days. Thus, in the {\sc Multistage} framework, instead of having only an instance of a problem and seeking a feasible solution optimizing its objective function, we have a sequence of instances of a problem, one for each time step and one is asked to seek a sequence of feasible solutions, one for each time step, reaching a trade-off between the optimality of the solutions and the stability of consecutive solutions.\\
The problem can be formalized as follows. We have a given time horizon $t=1,2,\ldots,T$, and a sequence of knapsack instances $I_1, I_2, \ldots,I_T$, one for each time step, defined on a set of $n$ productions units, also called objects in the {\sc Knapsack} problem. In every time step $t$ we have to choose a feasible knapsack $S_t$ of $I_t$, which gives a \textit{knapsack profit}. Taking into account transitions costs, we measure the stability/similarity of two consecutive solutions $S_t$ and $S_{t+1}$ by identifying the objects for which the decision, to be picked or not, remains the same in $S_t$ and $S_{t+1}$, giving a \textit{transition profit}. We are asked to produce a sequence of solutions $S_1, S_2, \ldots, S_T$ so that the total \textit{knapsack profit} plus the overall \textit{transition profit} is maximized.\\
There are a lot of other applications where it is beneficial to use a multistage framework. One of them is the {\sc facility location} problem, which we will develop later in this section. Another one is a musical application called the target-based computer-assisted orchestration. We will focus on this latter application in details in the last chapter of the document.\\

Let us now look at the example of Figure \ref{statickp} and consider both instances as a sequence of instances of a {\sc Multistage knapsack} problem with two time steps, the left instance being the instance at the time step $1$ and the right instance the one at the time step $2$. In order to compute a \textit{transition profit}, we need to introduce the notion of the bonus. Let us say that for this example, for each object, one gets a bonus $B=1$ if the object is taken or not taken for two consecutive time steps, i.e if the decision remains the same between time steps $t$ and $t+1$. Thus, the global \textit{transition profit} is equal to $B$ times the total number of decisions that remain the same between two consecutive time steps. For instance, if we take the objects of the static optimal solution, i.e object $u_3$ for the first time step and objects $u_1$ and $u_2$ for the second time step, the \textit{knapsack profit} is equal to $14$, $7$ at both time steps, but the value of the \textit{transition profit} is equal to $0$, none of the decisions remain the same, the object $u_1$ is taken only at time step $1$ whereas the objects $u_2$ and $u_3$ are taken only at the second time step, so we have a the global reward equal to $14$. The optimal solution consists of taking only the object $u_3$ at both time steps, getting a \textit{knapsack profit} equal to $7+5=12$ and all the \textit{transition profit}, as object $u_1$ and $u_2$ are not taken at both time steps and $u_3$ is taken at $t=1$ and $t=2$, i.e $3B = 3$ ; the global
reward is equal to $12+3=15$.\\

The example introduces the {\sc Knapsack} problem in its multistage configuration. This problem is the main subject of the second chapter where we will develop its particularities and properties.\\

Let us now give a formal definition of an optimization problem in its multistage version. 
\begin{definition}{(\emph{Multistage Optimization problem})} In a Multistage Optimization problem $\cal P$, we are given
\begin{itemize}
\item a number of steps $T \in \mathbb{N}$, a set $N$ of $n$ objects;
\item for any $t \in T$, an instance $I_t$ of the optimization problem. We will denote:
\begin{itemize}
\item $p_{t}$ the objective (profit/cost for maximization/minimization problems) function at time $t$
\item $\mathcal{F}_t\in 2^N$ the set of feasible solutions at time $t$
\end{itemize} 
%\item For each $t$: $C_t$ the capacity of knapsack at time $t$
\item $S_t$ a solution at a time step $t \in T$
\item $b(S_t,S_{t+1})$ the transition (bonus/cost for maximization/minimization problems) function between two solutions at consecutive time steps 
\item the value of a solution sequence $\mathcal{S}=(S_1,\dots,S_T)$ is $$f(\mathcal{S})=\sum_{t=1}^T p_t(S_t) + \sum_{t=1}^{T-1} b(S_t,S_{t+1})$$
We will use the term {\it profit}/cost for $ p_t(S_t)$ for maximization/minimization problems, transition {\it bonus}/cost for the transition bonus/transition cost $b(S_t,S_{t+1})$ for maximization/minimization problems, and {\it value} of a solution $\mathcal{S}$ for $f(\mathcal{S})$;
\item the goal is to determine a solution sequence of maximum/minimum value for maximization/minimization problems. 
\end{itemize}



\end{definition}

The definition presented above is of the few possible ways to define a problem in a multistage version. Indeed, here the global objective function consists of the sum of the profit/cost function and the transition bonus/cost.\\ This definition is quite arbitrary but seemed relevant for the problems encountered during the thesis. Moreover, it follows the original definition of the multistage framework presented in \cite{Gupta} and in \cite{Eisenstat}. It is in fact possible to define the objective function this way when one is able to compare the profit/cost function value and transition bonus/cost function value. For example, it is possible in the previously introduced applications, energy production planning or in data centers problems, the cost of the production  and turning cost of switching ON/OFF a reactor/server are directly comparable.\\
Another way of defining a global objective function for a problem in its multistage version is with a multi-objective function. Indeed, we will see later in this section that for some problems such as the {\sc vertex cover} problem, a multistage version of a problem was introduced where  
one is asked to minimize a number of selected nodes (the classical {\sc vertex cover} problem objective function) and also to minimize the number of modifications regarding the selected subset of nodes for two consecutive time steps. In some cases it is relevant to bound the number of changes between two consecutive time steps or even to bound them on the whole time horizon. \\

This latter point gives us the opportunity to talk about another choice made during the thesis.
In order to go further in the development of the multistage framework, we need to talk about some temporal settings on the knowledge of the data over the time horizon. Three settings are widely known and studied in the literature:
\begin{enumerate}
    \item the \emph{off-line} setting: one has a complete knowledge of the instance over the time horizon (this was the case of the example of Figure \ref{statickp} where we know the whole sequence of instances of the {\sc Multistage Knapsack} problem)
    \item the \emph{on-line} setting: at a time step $t$, one only knows the data for today, i.e we have no information regarding the instances at time steps $t+1,\ldots,T$. (another definition where one has also the knowledge of the instance at time $t+1$ is present in the literature). In our definition, we also assume that we know the number $T$ of time steps of the time horizon (another version also exists where this latter point is not known). The \emph{on-line} setting will be develop later in the chapter as it is a extensively studied case of temporal optimization.
    \item the \emph{k-lookahead} setting: at a time step $t$, one knows the data for today and the next $k$ days. This setting is tightly linked to the \emph{on-line} case as it is often used when no results can be obtained in the \emph{on-line} case. In our definition, we again assume that one knows the total number of time steps $T$ of the time horizon. (As in the \emph{on-line} setting, different versions regarding the knowledge of either the time step $t+1,\ldots,k$ and $T$ exist in the literature).
\end{enumerate}

The third chapter deals with Multistage Subset Maximization Problems in the \emph{on-line} and \emph{k-lookahead} settings. \\

\subsection{State of the art}

The multistage framework presented here follows the direction presented fairly recenlty by \cite{Gupta} and \cite{Eisenstat}.\\

In \cite{Gupta}, they studied the {\sc multistage matroid maintenance} problem, problem with some costs induced by changing decisions at some time steps on some edges and with an application quite similar to the one presented in our example. As a special case, the problem can be seen as a natural multistage version of the {\sc Spanning tree} problem, i.e one is aked to maintain a {\sc spanning tree} of a given graph at each time step.  They looked at both the \emph{on-line} and \emph{off-line} versions of the problem and gave logarithmic approximation algorithms in both cases using some LP-rounding, randomized algorithms and matroid techniques (see \cite{vazirani2013approximation} for details on approximation algorithms). They improved a result from \cite{buchbinder2012unified} and \cite{buchbinder2014competitive} who looked at a fractional version and later a more general version of the problem. They also showed that the {\sc perfect matching} problem in a multistage framework, a.k.a {\sc perfect matching maintenance}, becomes surprisingly inapproximable, even in the \emph{off-line} case. To do so, they did a reduction from the {\sc 3-colorability} problem, known to be NP-hard (see \cite{gj} for a definition of NP-hardness) in graph with bounded degrees, and more precisely with maximum degree 4 (\cite{guruswami2004hardness}). This last negative result is the first observation of the hardness induced by the multistage framework. Indeed, the majority of the problems studied for now and considered easy, i.e polynomial solvable or easily approximable, in their static form become really hard in this framework, even for limited restricted instances, in the \emph{off-line} case and for a small number of time steps.\\

In \cite{Eisenstat}, they addressed the {\sc facility location }problem in the multistage framework. The application underlying the study of this problem is another example of a possible application and need of stability in the decisions making among a time horizon. In our era, a huge amount of data are collected on social networks and their studies are more and more important. These networks quickly evolve in time and it is thus important to be able to analyze such data in a dynamic environment. Even though the {\sc facility location} problem have been widely studied in temporal settings, the notion of stability was not properly looked at. Taking into account this stability, here represented by clients moving or not between a set of facilities, paying an opening cost for the whole time horizon or paying some opening cost for each time step for every opened facility, gives the possibility to understand better clients behaviour and highlight the impact of clients moving through different facilities. It thus offers better results in realistic situations giving stable group partition of the network. They proposed a logarithmic approximation for the problem and gave a matching inapproximability result in restricted instances respecting the triangle inequalities, with only one client, two possible positions and a fixed opening cost, i.e once paid, the facility remains open for the whole time horizon. These instances admit a constant approximation ratio in the static framework. \\

In \cite{an2017dynamic}, they treated the left open question in \cite{Eisenstat} and presented a constant factor approximation algorithm using LP-rounding techniques for the version of the problem where opening cost are paid \textit{hourly}, i.e for each time step and for every opened facility.\\

The negative result on the {\sc perfect matching maintenance} was improved a few years later in \cite{bampis2018multistage}. Indeed, in \cite{Gupta}, it was shown that the problem was innaproximable for instances with as least $8$ time steps but the question for less time steps and for specific instances such as bipartite graph was left open. \cite{bampis2018multistage} addressed this open question and proved that the problem is hard to approximate. Then, they showed other negative results. Even the metric version of the problem where the triangle inequalities are satisfied, called {\sc minimum multistage perfect matching}, is APX-hard i.e does not have a PTAS (a formal definition of a PTAS is given in the second chapter). However, in the case where the number of time steps it equal to $2$ or $3$, they presented a constant approximation ratio. Finally, they also showed that the problem in its maximization version, with the complementary objective function, was also APX-hard even though it has a constant approximation ratio. \\

Very recently, in \cite{chimani2020approximating}, the authors looked again at the {\sc multistage matching} problem and a variant where the number of overall modifications are as small as possible. They improved the results presented in \cite{bampis2018multistage} by showing the NP-hardness of the problem in an even more restricted case than the one presented in \cite{bampis2018multistage}. They also presented a new approximation algorithm that does not require the restrictions needed before.
In \cite{bampis2018fair}, the authors looked at the {\sc max min fair allocation} problem, corresponding to a multistage version of the {\sc Santa klaus} problem. They studied the problem in the \emph{off-line}, \emph{on-line} and \emph{1-lookahead} settings and for different kind of evolving instances. The study of different kind of evolving instances is crucial in temporal optimization and will be developed in the third chapter. They showed that in its \emph{off-line} version, the problem is much harder than its static version. It becomes NP-hard even for simple instances without restriction whereas theses instances are trivially solved in the static version of the problem (instances where the static set of feasible solutions over the time horizon, i.e in this case instances where the set of resources and agents are the same during the whole time horizon and every resource can be allocated to any agent). Regarding the \emph{on-line} version of the problem, they proposed a constant competitive ratio for instances without restriction using an approximation algorithm for the static case as a subroutine. For instances where the feasible set of solution can change between different time steps, they showed that the problem has no bounded competitive ratio in the \emph{on-line} setting. Finally, they looked at the \emph{1-lookahead} version of the problem, in the same instance evolving setting and proposed a constant approximation algorithm using again a approximation algorithm for the static case as a subroutine. \\

\cite{olver2018itinerant} looked at the {\sc minimum linear arrangement} problem in a multistage framework, closely linked to the {\sc list update} problem. They studied both the \emph{off-line} setting, presenting a polylogarithmic approximation algorithm, and the  \emph{on-line} setting, giving a logarithmic lower bound on the competitive ratio of any randomized algorithm against an oblivious adversary. \\
Very recenlty, in \cite{fluschnik2019multistage}, a multistage version of the {\sc Vertex cover} problem is studied. They thus looked at a problem in temporal graphs, corresponding here to graphs with a fixed set of vertices but with a set of edges evolving during the time horizon. Temporal graphs are very well studied in temporal optimization and we will be presented more into details further in this chapter. The {\sc multistage vertex cover} problem differs a bit from the other multistage problems we presented before. Indeed, whereas the problems presented before share the notion of \textit{transition profit} or \textit{transition cost}, ensuring that the solution does not change too much over the time horizon, there is no bound over the number of changes in a decision one can make between two time steps. In the multistage version of the {\sc vertex cover} problem, one is asked to find a small subset of vertices covering the edges of a temporal graph, i.e a subset of vertices at each time step, such that the number of changes between two solutions of two consecutive time steps does not exceed a given parameter. They showed that in the case where the number of time steps of the problem can be anything, i.e not a constant, the {\sc Multistage vertex cover} is NP-hard even for one edge instances at every time step. Note that these instances are trivial in the static case. They also proved that the problem becomes NP-hard even for two time steps and on restricted instances where the graph of the first time step is a path and the one of the second time step is a tree. Then, they showed that if the parameter corresponding to the number of changes allowed between two time steps is smaller than two times the size of the cover, the problem is not fixed-parameter tractable (i.e W[1]-hard). The problem is appears to be FPT otherwise (see \cite{downey2012parameterized} for a survey on parameterized complexity). \\

In \cite{heeger2019multistage}, the authors also looked at the multistage framework in the parametrized version, with a constraint on the number of allowed modifications in the solutions selected in two consecutive time steps. A contrario to the one presented before where the constraint was local, they introduced a global constraint with a bound on the number total of modifications. They introduced the {\sc global multistage vertex cover} problem and proved that it is FPT by the upperbound of the size of the solution and by the number of time steps but W[1]-hard parametrized by the upperbound only. They also studied a global version of the {\sc min cut} problem giving some W[1]-harndess results. They finally highlighted that some polynomial-time solvable problems are harder, computationnaly speaker, in a global multistage framework than global multistage NP-hard problem. \\

Also last year, \cite{bampis2019lp} studied a wide variety of discrete minimization problems in a multistage framework. They presented some surprisingly positive results. Indeed, for some minimization integer programming problems refereed to as \textit{monotone} problems, polynomially solvable in their static version, such as the {\sc min cut} problem, they proved that the problems remain polynomially solvable in their multistage version. These results are surprising knowing that problems in the multistage framework presented before become much harder that their static version, problems solvable by a polynomial algorithm become NP-hard. They also showed that a known result in the static framework assuring both problems having the semi-integrality property and the {\sc vertex cover} problem are 2-approximable holds in the multistage framework. Finally they introduced a new rounding technique with two-threshold designed specially for multistage problems and proved some constant approximation ratio for multistage version of the {\sc Prize-Collecting Steiner Tree} problem and the {\sc Prize-Collecting Traveling Salesman} problem. \\

\alex{RAJOUTER papiers :
\begin{itemize}
    \item Multistage s-t Path: Confronting Similarity with Dissimilarity in Temporal Graphs
    \item Multistage Committee Election
\end{itemize}}\\

We presented the current state of the multistage framework. This setting is fairly recent but more and more studied with a lot of publications within the last few years. Indeed, authors keep improving the results and observations introduced in 2014 by \cite{Gupta} and \cite{Eisenstat}. Some surprising properties are being highlighted such as strong negative results (NP-hardness, inapproximability, W[1]-hardness) for very restricted instances (even sometimes for trivial instances in the static framework) and only a few time steps, problems polynomially solvable in a static version becoming harder than NP-hard problem, and also a few positive results, some problems keeping their static version properties in the multistage framework. The community looked at a few different settings regarding the evolution of the instances, the bonus/cost representing the stability, the knowledge over the time horizon, the parametrized version of the framework. Some of them will be developed later in the second and third chapter. The framework have still a lot of open questions and settings to be looked at. 


\alex{put toy examples when relevant in italic}\\

\section{Some other approaches}

We will develop here different branches of researches taking into account optimization problems with evolving data sets. We will see that some of them are very studied in the literature and that some others are closely linked to the multistage framework. For each temporal approach presented, we will focus on the similarities and differences from the multistage framework.



\alex{racourcir}\\
In an optimization problem, as said previously, given an instance, or a set of instances, one is asked to find a feasible solution, or a set of feasible solutions, optimizing an objective function. The feasibility is defined by a set of constraints applied to, depending on the nature of the problem, nodes, edges, precedence... for graphs, objects for packing problems...\\ A vast amount of optimization problems are known to be NP-hard, i.e not polynomially solvable and the complexity theory literature is based upon a central hypothesis, P$\ne$NP, stating that no polynomial algorithm can solved an NP-hard problem. The hardness of those problems make real world applications and implementations really difficult or even impossible. It is then naturally that about 30 years ago approximation algorithms were introduced. Those algorithms give some solutions in reasonable time, more precisely in polynomial time, even if they are not optimal. The quality of a solution outputed by such an algorithm is defined by a ratio, comparing its solution to the optimal solution. In most of the cases, this ratio consists of a constant multiplicative factor, inferior to $1$ for maximization problems and superior to $1$ for minimization problems, guaranteed or not. \\
In parallel of the development of the approximation approach, the temporal approach was elaborated. The idea leading to its introduction was motivated by the same concern, being able to emulate real world problems and solve them, optimally or not. Indeed, we presented for the multistage framework in the previous section some examples where a temporal approach is needed. In contrast of the fairly recent multistage framework, a lot of different temporal approaches have been developed, most of them since the early 1980's, responding to different applications and needs. We will focus on a few of them, being extensively studied and/or sharing some properties with the multistage one. \\

\textbf{Fully dynamic and reoptimization algorithms}\\
We will here present the fully dynamic and reoptimization algorithms. A more complete survey on these approaches is presented in \cite{boria2011survey} which our development is based on. At first and before the proper elaboration of the concept of reoptimization, fully dynamic algorithms were studied. Those algorithms mainly focused on some polynomial problem like the {\sc min spanning tree} (\cite{frederickson1985data}) and the {\sc shortest path} problem (\cite{even1985updating}). They were applied on data structures and were designed to maintain the optimality of a solution on instances subject to some perturbations. The reoptimization notion was later introduced in \cite{archetti2003reoptimizing}. The authors addressed the {\sc travelling salesman} problem, a very well know NP-hard problem, and considered two distinct steps. In a first step, an algorithm gives an optimal or approximate solution for a NP-hard problem in a static framework. The reoptimization focuses on the second step where the instance is perturbed, i.e vertex or edge deletions for graph problems, changing values for numerical problems ... one is then asked to maintain the optimality/approximation ratio of the solution. \\
This two steps give direct property for problem in their reoptimization version. Indeed, the result of NP-hardness of a problem holds in the reoptimization framework. However, some problems are known to be hard to approximate in their static version and becomes APX or even admits a PTAS in the reoptimization framework (it is the case for example for the {\sc max independ set} problem). This is why the majority of the results presented in this framework concern approximation algorithm. More generally, two kinds of results can be achieved for NP-hard problems in their reoptimization version. Either the algorithm achieve to
stable resultat \\
mfcs refs \\
deux points de paschos\\
complexite amortie ?? \\

 

A survey on combinatorial optimization in dynamic environments Paschos\\
amortized complexity

\subsectionToc{reoptimization}

book : \\
On the Hardness of Reoptimization Hans-Joachim B√∂ckenhauer\\

On the Tradeoff between Stability and Fit
EDITH COHEN : "Two hugely popular models are metrical task systems, where the goal is to maximize average fit per average change [Borodin et al. 1992] and regret minimization used in decision theory."\\ 


\subsectionToc{online}
optima 54 Susanne Albers\\
regularization\\
competitive ratio\\


Competitive Analysis via Regularization
Niv Buchbinder Shahar Chen Joseph (Seffi) Naor\\

book : \\
Online Algorithms
The State of the Art\\

Online Optimization jaillet \\
\subsectionToc{incremental setting?}
\subsectionToc{online learning}
Buchbinder et al. [14] and Buchbinder, Chen and Naor [13] considered also a multistage model and studied the re- lation between the online learning and competitive analysis frameworks, mostly for fractional optimization problems.\\     
prediction? randomization\\
N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University Press, 2006\\

Unified Algorithms for Online Learning and Competitive Analysis
Niv Buchbinder
\\

\subsectionToc{Online stochastic combinatorial optimization}



\subsectionToc{dynamic parameterized complexity}
Reoptimization of Parameterized Problems Hans-Joachim Bockenhauer\\

\subsectionToc{temporal/dynamic graphs}

Dynamic Graph Algorithms Giuseppe F. Italiano\\
when a solution is taken the instance, edges or vertices change \\
DATA STRUCTURES FOR ON-LINE UPDATING OF
MINIMUM SPANNING TREES, WITH APPLICATIONS*\\

\alex{temporal spirachis, existence de chemins, flow}\\
\chapter{Multistage Knapsack Problem}

define PTAS
\chapter{Online Multistage Subset Maximisation Problems}
Let us now define formally a class of problems, the Subset Maximisation Problems and then its multistage version.

\begin{definition}

\emph{(Subset Maximization Problems.)} A Subset Maximization problem $\cal P$ is a combinatorial optimization problem whose instances $I=(N,p,\mathcal{F})$ consist of
\begin{itemize}
    \item A ground set $N$;
    \item A set $\mathcal{F}\subseteq 2^N$ of feasible solutions such that $\emptyset\in\mathcal{F}$;
    \item A non-negative weight $p(S)$ for every $S \in \mathcal{F}$.
\end{itemize}
The goal is to find $S^*\in \mathcal{F}$ such that $p(S^*)=\max\{p(S):S\in\mathcal{F}\}$.
\end{definition}
This is a very general class of problems, including the maximization \emph{Subset Selection} problems studied by Pruhs and Woeginger in (\cite{Pruhs}) (they only considered linear objective functions). It contains for instance graph problems where $N$ is the set of vertices (as in any maximization induced subgraph problem verifying some property) or the set of edges (as in  matching problems). It also contains classical set problems (knapsack, maximum 3-dimensional matching,\dots), and more generally 0-1 linear programs (with non negative profits in the objective function).
Given a problem in the previous class, we are interested in its multistage version.
The stability over time of a solution sequence is classically captured by considering a \textit{transition cost} when a modification is made in the solution. Here, dealing with maximization problems, we will consider a transition {\it bonus} $B$ for taking into account the similarity of two consecutive solutions.
In what follows, we will use the term object to denote an element of $N$ (so an object can be a vertex of a graph, or an edge,\dots, depending on the underlying problem). 	%\textcolor{red}{Kevin: were we assuming anywhere now that $\emptyset$ is feasible?}
\begin{definition}
\emph{(Multistage Subset Maximization Problems.)} In a Multistage Subset Maximization problem $\cal P$, we are given
\begin{itemize}
\item a number of steps $T \in \mathbb{N}$, a set $N$ of $n$ objects;
\item for any $t \in T$, an instance $I_t$ of the optimization problem. We will denote:
\begin{itemize}
\item $p_{t}$ the objective (profit) function at time $t$
\item $\mathcal{F}_t\in 2^N$ the set of feasible solutions at time $t$
\end{itemize} 
%\item For each $t$: $C_t$ the capacity of knapsack at time $t$
\item $B \in \mathbb{R^{+}}$ a given \textit{transition profit}. 
\item the value of a solution sequence $\mathcal{S}=(S_1,\dots,S_T)$ is $$f(\mathcal{S})=\sum_{t=1}^T p_t(S_t) + \sum_{t=1}^{T-1} b(S_t,S_{t+1})$$
where $b(S_t,S_{t+1})$ is the transition bonus for the solution between time steps $t$ and $t+1$. We will use the term {\it profit} for $ p_t(S_t)$, {\it bonus} for the transition bonus $b(S_t,S_{t+1})$, and {\it value} of a solution $\mathcal{S}$ for $f(\mathcal{S})$;
\item the goal is to determine a solution sequence of maximum value. 
\end{itemize}
\end{definition}

The definition above defined formally a general class of maximization problems in a multistage setting. It is possible to define in a similar way a general class of multistage minimization problems, the main difference is that in a minimization problem, we don't consider a bonus but a cost and a \textit{transition cost} induced by changing our decisions between two consecutive time steps.

\chapter{Target-based computer-assisted orchestration: a theoretical analysis}
\pagenumbering{arabic}

%\sectionToc{Contenu de ce document}
\bibliographystyle{apalike}
\bibliography{biblio}


\end{document}
